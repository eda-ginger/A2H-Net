{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2025.05.21 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "data = pd.read_csv('data/AF_data_info.csv')\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read PDB File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdb(pdb_path):\n",
    "    records = []\n",
    "    with open(pdb_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(('ATOM', 'HETATM')):\n",
    "                record = {\n",
    "                    'record': line[0:6].strip(),\n",
    "                    'atom_serial': int(line[6:11]),\n",
    "                    'atom_name': line[12:16].strip(),\n",
    "                    'alt_loc': line[16],\n",
    "                    'res_name': line[17:20].strip(),\n",
    "                    'chain_id': line[21],\n",
    "                    'res_seq': int(line[22:26]),\n",
    "                    'i_code': line[26],\n",
    "                    'x': float(line[30:38]),\n",
    "                    'y': float(line[38:46]),\n",
    "                    'z': float(line[46:54]),\n",
    "                    'occupancy': float(line[54:60]),\n",
    "                    'b_factor': float(line[60:66]),\n",
    "                    'element': line[76:78].strip(),\n",
    "                    'charge': line[78:80].strip()\n",
    "                }\n",
    "                records.append(record)\n",
    "    records = pd.DataFrame(records)\n",
    "    records = records[records['element'] != 'H']\n",
    "    return records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Mol2 to PDB format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mol2(mol2_path, ligand=False):\n",
    "    with open(mol2_path) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    if ligand:\n",
    "        atom_start = next(i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>ATOM'))\n",
    "        bond_start = next(i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>BOND'))\n",
    "        atom_end = bond_start\n",
    "        atom_lines = lines[atom_start+1:atom_end]\n",
    "        return ligand_reader(atom_lines)\n",
    "    \n",
    "    else:\n",
    "        atom_start = next(i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>ATOM'))\n",
    "        bond_start = next(i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>BOND'))\n",
    "        chain_start = next(i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>SUBSTRUCTURE'))\n",
    "        set_start = next(i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>SET'))\n",
    "\n",
    "        atom_end = bond_start\n",
    "        bond_end = chain_start\n",
    "        chain_end = set_start\n",
    "\n",
    "        atom_lines = lines[atom_start+1:atom_end]\n",
    "        bond_lines = lines[bond_start+1:bond_end]\n",
    "        chain_lines = lines[chain_start+1:chain_end]\n",
    "        return to_pdb_format(atom_lines, bond_lines, chain_lines)\n",
    "\n",
    "\n",
    "def ligand_reader(atom):\n",
    "    records = []\n",
    "    for idx, line in enumerate(atom):\n",
    "        fields = line.split()\n",
    "        atom_id = int(fields[0])\n",
    "        atom_name = fields[1]\n",
    "        x, y, z = map(float, fields[2:5])\n",
    "        atom_type = fields[5]\n",
    "        resid = int(fields[6])\n",
    "        resname_full = fields[7]\n",
    "        res_name = resname_full[:3]\n",
    "        occupancy = 1.0\n",
    "        b_factor = 0.0\n",
    "        element = atom_type.split('.')[0][0].upper()\n",
    "        charge = fields[8] if len(fields) > 8 and fields[8].replace('.', '', 1).replace('-', '', 1).isdigit() else ''\n",
    "        record = {\n",
    "            'record': 'ATOM',\n",
    "            'atom_serial': atom_id,\n",
    "            'atom_name': atom_name,\n",
    "            'alt_loc': '',\n",
    "            'res_name': res_name,\n",
    "            'chain_id': '',\n",
    "            'res_seq': resid,\n",
    "            'i_code': '',\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'z': z,\n",
    "            'atom_type': atom_type,\n",
    "            'occupancy': occupancy,\n",
    "            'b_factor': b_factor,\n",
    "            'element': element,\n",
    "            'charge': charge\n",
    "        }\n",
    "        records.append(record)\n",
    "    records = pd.DataFrame(records)\n",
    "    records = records[records['element'] != 'H']       \n",
    "    return records.reset_index(drop=True)\n",
    "\n",
    "\n",
    "def parse_substructure(lines):\n",
    "    substructures = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        sub = {\n",
    "            'id': int(parts[0]),\n",
    "            'name': parts[1],\n",
    "            'root_atom': int(parts[2]),\n",
    "            'type': parts[3],\n",
    "            'dict_type': parts[4],\n",
    "            'chain': parts[5],\n",
    "            'residue': parts[6],\n",
    "            'unk': parts[7],\n",
    "            'status': parts[8],\n",
    "        }\n",
    "        substructures.append(sub)\n",
    "    return pd.DataFrame(substructures)\n",
    "\n",
    "\n",
    "def to_pdb_format(atom, bond, chain):\n",
    "    records = []\n",
    "    chains = parse_substructure(chain)\n",
    "    \n",
    "    box = {}\n",
    "    prev = None\n",
    "    root_atom_chain = None\n",
    "    chain_atoms = [1]\n",
    "    for idx, line in enumerate(atom):\n",
    "        fields = line.split()\n",
    "        atom_id = int(fields[0])\n",
    "        atom_name = fields[1]\n",
    "        x, y, z = map(float, fields[2:5])\n",
    "        atom_type = fields[5]\n",
    "        resid = int(fields[6])\n",
    "        \n",
    "        resname_full = fields[7]\n",
    "        res_name = resname_full[:3]\n",
    "        \n",
    "        if idx == 0:\n",
    "            prev = resid\n",
    "        else:\n",
    "            if resid == prev:\n",
    "                chain_atoms.append(atom_id)\n",
    "            else:\n",
    "                for a in chain_atoms:\n",
    "                    box[a] = root_atom_chain\n",
    "                prev = resid\n",
    "                chain_atoms = [atom_id]\n",
    "\n",
    "        if atom_id in chains['root_atom'].values:\n",
    "            chain_id = chains[chains['root_atom'] == atom_id]['chain'].values[0]\n",
    "            root_atom_chain = chain_id\n",
    "        else:\n",
    "            chain_id = None\n",
    "            \n",
    "        occupancy = 1.0\n",
    "        b_factor = 0.0\n",
    "        element = atom_type.split('.')[0][0].upper()\n",
    "        charge = fields[8] if len(fields) > 8 and fields[8].replace('.', '', 1).replace('-', '', 1).isdigit() else ''\n",
    "        record = {\n",
    "            'record': 'ATOM',\n",
    "            'atom_serial': atom_id,\n",
    "            'atom_name': atom_name,\n",
    "            'alt_loc': '',\n",
    "            'res_name': res_name,\n",
    "            'chain_id': chain_id,\n",
    "            'res_seq': resid,\n",
    "            'i_code': '',\n",
    "            'x': x,\n",
    "            'y': y,\n",
    "            'z': z,\n",
    "            'atom_type': atom_type,\n",
    "            'occupancy': occupancy,\n",
    "            'b_factor': b_factor,\n",
    "            'element': element,\n",
    "            'charge': charge\n",
    "        }\n",
    "        records.append(record)\n",
    "    \n",
    "    records = pd.DataFrame(records)\n",
    "    records = records[records['element'] != 'H']       \n",
    "    records['chain_id'] = records['atom_serial'].map(box)\n",
    "    return records.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Pocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "amino_acids = {\n",
    "    'ALA': 'A', 'ARG': 'R', 'ASN': 'N', 'ASP': 'D',\n",
    "    'CYS': 'C', 'GLU': 'E', 'GLN': 'Q', 'GLY': 'G',\n",
    "    'HIS': 'H', 'ILE': 'I', 'LEU': 'L', 'LYS': 'K',\n",
    "    'MET': 'M', 'PHE': 'F', 'PRO': 'P', 'SER': 'S',\n",
    "    'THR': 'T', 'TRP': 'W', 'TYR': 'Y', 'VAL': 'V'\n",
    "    }\n",
    "\n",
    "rev_amino_acids = {v: k for k, v in amino_acids.items()}\n",
    "\n",
    "modified_residue_map = {\n",
    "    \"MSE\": \"M\",  # Selenomethionine → Methionine\n",
    "    \"SEP\": \"S\",  # Phosphoserine → Serine\n",
    "    \"TPO\": \"T\",  # Phosphothreonine → Threonine\n",
    "    \"PTR\": \"Y\",  # Phosphotyrosine → Tyrosine\n",
    "    \"HYP\": \"P\",  # Hydroxyproline → Proline\n",
    "    \"KCX\": \"K\",  # Carboxylysine → Lysine\n",
    "    \"CSO\": \"C\",  # Oxidized cysteine → Cysteine\n",
    "    \"CGU\": \"E\",  # γ-carboxy-glutamate → Glutamic Acid\n",
    "    \"F2F\": \"F\",  # Fluorophenylalanine → Phenylalanine\n",
    "    \"ASH\": \"D\",  # Protonated Aspartic Acid → Aspartic Acid\n",
    "    \"GLH\": \"E\",  # Protonated Glutamic Acid → Glutamic Acid\n",
    "    \"CYX\": \"C\",  # Disulfide-bonded Cysteine → Cysteine\n",
    "    \"HID\": \"H\",  # Neutral Histidine (delta-protonated)\n",
    "    \"HIE\": \"H\",  # Neutral Histidine (epsilon-protonated)\n",
    "    \"HIP\": \"H\",  # Positively charged Histidine\n",
    "}\n",
    "def parse_residue_and_align(lst, chain=True):\n",
    "    result = []\n",
    "    prev = None\n",
    "    seen_counts = {}\n",
    "    \n",
    "    if chain:\n",
    "        \n",
    "        for num, chain in lst:\n",
    "            if num == prev:\n",
    "                continue\n",
    "            count = seen_counts.get(num, 0) + 1\n",
    "            seen_counts[num] = count\n",
    "            key = (f\"{num}\" if count == 1 else f\"{num}-{count}\", chain)\n",
    "            result.append(key)\n",
    "            prev = num\n",
    "        result = {k: v for k, v in result}\n",
    "    \n",
    "    else:    \n",
    "        for num in lst:\n",
    "            if num == prev:\n",
    "                result.append(key)\n",
    "                continue \n",
    "            count = seen_counts.get(num, 0) + 1\n",
    "            seen_counts[num] = count\n",
    "            key = f\"{num}\" if count == 1 else f\"{num}-{count}\"\n",
    "            result.append(key)\n",
    "            prev = num\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "def read_residue(res):\n",
    "    global amino_acids\n",
    "\n",
    "    init = 0\n",
    "    result = []\n",
    "    res_dict = {}\n",
    "    already = set()\n",
    "    for r, c, idx, ic in res:\n",
    "        if r == 'HOH':\n",
    "            continue\n",
    "        if r not in amino_acids:\n",
    "            conv_r = 'X'\n",
    "        else:\n",
    "            conv_r = amino_acids[r]\n",
    "        key = (c, idx, ic)\n",
    "        if key in already:\n",
    "            continue\n",
    "        already.add(key)\n",
    "        result.append(conv_r)\n",
    "        res_dict[key] = init\n",
    "        init += 1\n",
    "    rev_res_dict = {v: k for k, v in res_dict.items()}\n",
    "    return ''.join(result), res_dict, rev_res_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyMOL Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pymol\n",
    "from pymol import cmd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "# pymol.finish_launching() # if you see the work in pymol, you need to run this\n",
    "\n",
    "\n",
    "def align_and_save(apo_path, holo_path, output_path):\n",
    "    cmd.reinitialize()  # Clear previous structures\n",
    "    cmd.load(str(apo_path), 'apo')\n",
    "    cmd.load(str(holo_path), 'holo')\n",
    "    alignment_info = cmd.super('apo', 'holo')\n",
    "    cmd.save(str(output_path), 'apo')\n",
    "    rmsd = alignment_info[0]  # RMSD\n",
    "    return rmsd\n",
    "\n",
    "\n",
    "def point_mutation(apo_path, output_path, mutations):\n",
    "    global rev_amino_acids\n",
    "    cmd.reinitialize()  # Clear previous structures\n",
    "    cmd.load(apo_path, 'apo')\n",
    "    cmd.wizard('mutagenesis')\n",
    "    for row in mutations:\n",
    "        chain, resid, ap_res, ho_res = map(str, row)\n",
    "        # PyMOL residue selection: /object//chain/resi\n",
    "        if ho_res == 'X':\n",
    "            continue\n",
    "        selection = f'/apo//{chain}/{resid}/'\n",
    "        print(f'selcction: {selection}')\n",
    "        print(f'apo: {ap_res} -> holo: {ho_res}')\n",
    "        cmd.get_wizard().set_mode(rev_amino_acids[ho_res])\n",
    "        cmd.get_wizard().do_select(selection)\n",
    "        cmd.get_wizard().apply()\n",
    "    cmd.set_wizard()\n",
    "    cmd.save(output_path, 'apo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## APO Align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# 로그 설정\n",
    "out = Path('data/raw/af_align')\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "log_path = out / \"processing.log\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s %(levelname)s: %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_path, mode='w'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pocket_idx = pd.read_csv('data/raw/pocket_idx.tsv', sep='\\t')\n",
    "pocket_idx.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_pdbbind = ['1mh5', '1d6v', '1ct8', '1i7z', '1a4k', '1a0q', '1i6v', '1c12', '2qhr', '4nyi', '4nyj', '4nym', '2hrp', '3eql', '4kmu', '4kn4', '4kn7', '2mpa', '1kcs', '1zyr']\n",
    "no_csar = ['1gz9', '2v7t', '2j4k', '2v7u', '1swk', '2vhw', '1gzc', '1bcj', '2hr6']\n",
    "no_match = no_pdbbind + no_csar\n",
    "print(len(no_match)) # no match pocket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 72mins\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "def sequence_reader(df):\n",
    "    atom_end = df[df['record'] == 'ATOM'].index[-1]\n",
    "    main_structure = df[:atom_end]\n",
    "    read, ridx, r_ridx = read_residue(df[:atom_end][['res_name', 'chain_id', 'res_seq', 'i_code']].values)\n",
    "    return main_structure, read, ridx, r_ridx\n",
    "\n",
    "\n",
    "def find_root_atom(df):\n",
    "    return df[df['atom_name'] == 'CA'][['chain_id', 'res_seq', 'i_code']].values\n",
    "\n",
    "\n",
    "def find_atom(df, keys):\n",
    "    result = []\n",
    "    for k in keys:\n",
    "        result.append(df[(df['chain_id'] == k[0]) & (df['res_seq'] == k[1]) & (df['i_code'] == k[2])])\n",
    "    result = pd.concat(result).reset_index(drop=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "count = 0\n",
    "max_mutation = 0\n",
    "\n",
    "rmsd_results = {}\n",
    "apo_path = Path('data/raw/afdb')\n",
    "holo_path = Path('data/raw/pdb')\n",
    "\n",
    "# output path\n",
    "apo_align_path = Path('data/raw/af_align')\n",
    "apo_align_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "mutant_path = Path('data/raw/mutant')\n",
    "mutant_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "a2h_path = Path('data/processed/a2h')\n",
    "a2h_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# main loop\n",
    "num = 0\n",
    "for idx, row in data.iterrows():\n",
    "    pdb = row['PDB']\n",
    "    uni = row['UniProt']\n",
    "    st = row['SET']\n",
    "\n",
    "    # logging.info(f\"\\n[{idx+1}/{len(data)}] Processing code: {pdb}\")\n",
    "    \n",
    "    if pdb in no_match:\n",
    "        continue\n",
    "\n",
    "    if st == 'PDB':\n",
    "        continue\n",
    "    \n",
    "    elif st != 'CSAR':\n",
    "        continue\n",
    "        # path\n",
    "        apo = apo_path / f\"AF-{uni}-F1-model_v4.pdb\"    \n",
    "        holo = holo_path / st / pdb / f\"{pdb}_protein.pdb\"\n",
    "        pocket = holo_path / st / pdb / f\"{pdb}_pocket.pdb\"\n",
    "        \n",
    "        # read pdb format\n",
    "        ap = read_pdb(apo)\n",
    "        ho = read_pdb(holo)\n",
    "        pk = read_pdb(pocket)\n",
    "        \n",
    "        # read pocket and parse chain_id from holo\n",
    "        ho_keys = parse_residue_and_align(ho[['res_seq', 'chain_id']].values)\n",
    "        pk['c_key'] = parse_residue_and_align(pk['res_seq'].values, chain=False)\n",
    "        pk['chain_id'] = pk['c_key'].map(ho_keys)\n",
    "        pk = pk.drop(columns=['c_key']).reset_index(drop=True)\n",
    "        pk.loc[pk['res_name'] == 'HOH', 'chain_id'] = ' '\n",
    "\n",
    "    else: # CSAR\n",
    "        # continue # pocket이 잘못만들어짐.. ㅅㅂ 내 시간.. 그냥 mol2파일에서 9옴스트롬이내 추출 ㄱㄱ\n",
    "        \n",
    "        # path\n",
    "        apo = apo_path / f\"AF-{uni}-F1-model_v4.pdb\"\n",
    "        holo = [f for f in(holo_path / st / pdb).glob('*complex.mol2')][0]\n",
    "        pocket = pocket_idx[pocket_idx['PDB'] == pdb]['Residue'].values[0]\n",
    "        \n",
    "        # read for pdb format\n",
    "        ap = read_pdb(apo)\n",
    "        ho = read_mol2(holo)\n",
    "        \n",
    "        # read pocket index from DeepDTAF/CAPLA SSEs\n",
    "        if pdb in ['2jj3', '2fai', '2r6w', '2z4b']:\n",
    "            continue\n",
    "\n",
    "        pk_sse = []\n",
    "        for pk_idx in pocket.split(','):\n",
    "            \n",
    "            if pk_idx[0].isalpha():\n",
    "                pk_chain, pk_res_seq = pk_idx[0], pk_idx[1:]\n",
    "            else:\n",
    "                pk_chain, pk_res_seq = '2', pk_idx[1:]\n",
    "\n",
    "            if pk_res_seq[-1].isalpha():\n",
    "                pk_res_seq, pk_i_code = pk_res_seq[:-1], pk_res_seq[-1]\n",
    "            else:\n",
    "                pk_i_code = ''\n",
    "            \n",
    "            pk_sse.append((pk_chain, int(pk_res_seq), pk_i_code))\n",
    "        pk = find_atom(ho, pk_sse)\n",
    "\n",
    "    num += 1\n",
    "    if num % 1000 == 0:\n",
    "        print(num)\n",
    "\n",
    "    # # common process\n",
    "    # extract amino acid sequence\n",
    "    ho_main, ho_read, ho_ridx, ho_r_ridx = sequence_reader(ho)\n",
    "    pk_main, pk_read, pk_ridx, pk_r_ridx = sequence_reader(pk)\n",
    "    ap_main, ap_read, ap_ridx, ap_r_ridx = sequence_reader(ap)\n",
    "    # print(len(ho_ridx), ho_read)\n",
    "    # print(len(pk_ridx), pk_read)\n",
    "    # print(len(ap_ridx), ap_read)\n",
    "\n",
    "    # search pocket in holo\n",
    "    pk_ca = find_root_atom(pk_main)\n",
    "    ho_pk = find_atom(ho_main, pk_ca)\n",
    "    ho_ca = find_root_atom(ho_pk)\n",
    "    ho_pk_idx = sorted([ho_ridx[(idx[0], idx[1], idx[2])] for idx in ho_ca])\n",
    "    \n",
    "    # extract pocket amino acids in holo (save position)\n",
    "    ho_pk_read = ho_read[ho_pk_idx[0]:ho_pk_idx[-1]+1]\n",
    "    ho_pk_res_dict = {ho_pk_idx[0] + i:i  for i in range(len(ho_pk_read))}\n",
    "    ho_pk_res_idx = [ho_pk_res_dict[i] for i in ho_pk_idx] # for mutation position\n",
    "    \n",
    "    # sequence alignment (score params: match, mismatch, gap open, gap extension)\n",
    "    alignments = pairwise2.align.localms(ho_pk_read, ap_read, 2, -1, -5, -1)\n",
    "    ho_align, ap_align = alignments[0][:2]\n",
    "\n",
    "    # mapping position & check mutation\n",
    "    mapping_align = {}\n",
    "    align_position = {}\n",
    "    mutations = []\n",
    "    st_pos = ho_pos = ap_pos = -1\n",
    "\n",
    "    for a, b in zip(ho_align, ap_align):\n",
    "        if a != '-':\n",
    "            ho_pos += 1\n",
    "            st_pos += 1\n",
    "        if b != '-':\n",
    "            ap_pos += 1\n",
    "            st_pos += 1\n",
    "        if a != '-' and b != '-':\n",
    "            st_pos += 1\n",
    "            align_position[st_pos] = ho_pos\n",
    "            mapping_align[ho_pos] = ap_pos\n",
    "            if a != b and ho_pos in ho_pk_res_idx:\n",
    "                mutations.append((ap_pos, b, a))\n",
    "                \n",
    "    # check mutation\n",
    "    if mutations:\n",
    "        max_mutation = max(max_mutation, len(mutations))\n",
    "\n",
    "        transform = []\n",
    "        for mut in mutations:\n",
    "            ap_pk_idx, ap_res, ho_res = mut\n",
    "            ap_chain, ap_resid, _ = ap_r_ridx[ap_pk_idx]\n",
    "            transform.append((ap_chain, ap_resid, ap_res, ho_res))\n",
    "        \n",
    "        mut_out = mutant_path / f\"AF-{uni}-mut-{pdb}.pdb\"    \n",
    "        point_mutation(apo, mut_out, transform)\n",
    "\n",
    "        # reload\n",
    "        apo = mut_out\n",
    "        ap = read_pdb(apo)\n",
    "        ap_main, ap_read, ap_ridx, ap_r_ridx = sequence_reader(ap)\n",
    "\n",
    "    # find pocket in apo (ho_pk_idx -> ho_pk_res_dict -> mapping align)\n",
    "    ap_ca = []\n",
    "    rm_ca = []\n",
    "    for i in ho_pk_idx:\n",
    "        hp_key = ho_pk_res_dict[i]  # atom within pocket\n",
    "        if hp_key in mapping_align.keys(): # atom within mapping & pocket\n",
    "            ap_ca.append(ap_r_ridx[mapping_align[hp_key]]) # find \n",
    "        else:\n",
    "            rm_ca.append(i)\n",
    "    if rm_ca: # select atom atoms only in apo\n",
    "        ho_pk = find_atom(ho_main, [ho_r_ridx[i] for i in ho_pk_idx if not i in rm_ca])\n",
    "    ap_pk = find_atom(ap_main, ap_ca) # find pocket in apo\n",
    "\n",
    "    # superimpose\n",
    "    align_out = apo_align_path / f\"AF-{uni}-align-{pdb}.pdb\"\n",
    "    rmsd = align_and_save(apo, holo, align_out)\n",
    "    rmsd_results[pdb] = rmsd\n",
    "    \n",
    "    # mutated & aligned apo structure\n",
    "    aa = read_pdb(align_out)\n",
    "    aa_main, aa_read, aa_ridx, aa_r_ridx = sequence_reader(aa)\n",
    "    aa_pk = find_atom(aa_main, ap_ca)\n",
    "    \n",
    "    # save\n",
    "    a2h_out = a2h_path / f\"{pdb}_a2h.pkl\"\n",
    "    a2h = {'APO': aa_pk, 'HOLO': ho_pk}\n",
    "    with open(a2h_out, 'wb') as f:\n",
    "        pd.to_pickle(a2h, f)\n",
    "\n",
    "    # if len(mutations) >= 1:\n",
    "    #     print(pdb)\n",
    "    #     print(format_alignment(*alignments[0]))\n",
    "    #     print(sequence_reader(ho_pk)[1])\n",
    "    #     print(sequence_reader(ap_pk)[1])        \n",
    "    #     print()\n",
    "    #     break\n",
    "    \n",
    "\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(a2h_out, 'rb') as f:\n",
    "    loaded_bundle = pd.read_pickle(f)\n",
    "loaded_bundle['HOLO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_bundle['APO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(rmsd_results.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "intereset = '2xxw'\n",
    "with open(a2h_path / f\"{intereset}_a2h.pkl\", 'rb') as f:\n",
    "    lb = pd.read_pickle(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb['APO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb['HOLO']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sequence_reader(lb['APO'])[1])\n",
    "print(sequence_reader(lb['HOLO'])[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2025.05.23 \n",
    "- sampling validation set in refined set (randomly)\n",
    "- CSAR pocket search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def find_pocket_residues(complex_df: pd.DataFrame, ligand_df: pd.DataFrame, cutoff: float = 10.0):\n",
    "    ligand_df = ligand_df.reset_index(drop=True)\n",
    "    complex_df = complex_df.reset_index(drop=True)\n",
    "    ligand_coords = ligand_df[['x', 'y', 'z']].to_numpy()\n",
    "    protein_df = complex_df[~complex_df['res_name'].isin(ligand_df['res_name'].unique())].copy()\n",
    "    protein_df = protein_df.reset_index(drop=True)\n",
    "    protein_coords = protein_df[['x', 'y', 'z']].to_numpy()\n",
    "    \n",
    "    # calculate distance between ligand and protein\n",
    "    dist_matrix = cdist(ligand_coords, protein_coords)\n",
    "    \n",
    "    # extract indices of atoms within cutoff\n",
    "    close_idx = np.where(dist_matrix <= cutoff)[1]\n",
    "    close_atoms = protein_df.iloc[close_idx]\n",
    "\n",
    "    # extract pocket residues\n",
    "    pocket_residues = {\n",
    "        (row['chain_id'], row['res_seq'], row['i_code'])\n",
    "        for _, row in close_atoms.iterrows()\n",
    "    }\n",
    "    pocket_df = find_atom(complex_df, pocket_residues)\n",
    "    return pocket_df\n",
    "\n",
    "\n",
    "def write_pocket_to_mol2(pocket_df: pd.DataFrame, output_path: str):\n",
    "    pocket_df = pocket_df.reset_index(drop=True)\n",
    "    pocket_df['atom_id'] = np.arange(1, len(pocket_df) + 1)\n",
    "    pocket_df[['x', 'y', 'z', 'charge']] = pocket_df[['x', 'y', 'z', 'charge']].astype(float)\n",
    "\n",
    "    with open(output_path, 'w') as f:\n",
    "        # MOLECULE section\n",
    "        f.write(\"@<TRIPOS>MOLECULE\\n\")\n",
    "        f.write(\"POCKET\\n\")\n",
    "        f.write(f\"{len(pocket_df)} 0 1\\n\")\n",
    "        f.write(\"PROTEIN\\n\")\n",
    "        f.write(\"USER_CHARGES\\n\\n\")\n",
    "\n",
    "        # ATOM section\n",
    "        f.write(\"@<TRIPOS>ATOM\\n\")\n",
    "        for _, row in pocket_df.iterrows():\n",
    "            f.write(\n",
    "                f\"{row['atom_id']:>7} {row['atom_name']:<8} \"\n",
    "                f\"{row['x']:>10.4f} {row['y']:>10.4f} {row['z']:>10.4f} \"\n",
    "                f\"{row['atom_type']:<6} {row['res_seq']:>5} {row['res_name']:<8} \"\n",
    "                f\"{row.get('charge', 0.0):>9.4f}\\n\"\n",
    "            )\n",
    "\n",
    "        # BOND section (empty)\n",
    "        f.write(\"@<TRIPOS>BOND\\n\")\n",
    "\n",
    "\n",
    "def read_csar(mol2_path):\n",
    "    mol2_path = Path(mol2_path)\n",
    "    output_path = mol2_path.parent / f'{mol2_path.parent.stem}_ligand.mol2'\n",
    "\n",
    "    with open(mol2_path) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    atom_start = next(i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>ATOM'))\n",
    "    bond_start = next(i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>BOND'))\n",
    "    chain_start = next(i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>SUBSTRUCTURE'))\n",
    "    set_start = next((i for i, l in enumerate(lines) if l.startswith('@<TRIPOS>SET')), len(lines))\n",
    "\n",
    "    atom_lines = lines[atom_start+1:bond_start]\n",
    "    bond_lines = lines[bond_start+1:chain_start]\n",
    "    chain_lines = lines[chain_start+1:set_start]\n",
    "\n",
    "    # --- parse ligand definition ---\n",
    "    ligand_line_idx = next(i for i, l in enumerate(lines) if l.strip().startswith(\"LIGAND\"))\n",
    "\n",
    "    ligand_atom_ids = []\n",
    "    i = ligand_line_idx + 1\n",
    "    while i < len(lines):\n",
    "        line = lines[i].strip()\n",
    "        if not line or not line.split()[0].isdigit():\n",
    "            break\n",
    "        ligand_atom_ids.extend(int(token) for token in line.split() if token.isdigit())\n",
    "        i += 1\n",
    "\n",
    "    ligand_atom_ids_set = set(ligand_atom_ids[1:])\n",
    "    ligand_atom_lines = [l for l in atom_lines if int(l.split()[0]) in ligand_atom_ids_set]\n",
    "    ligand_atom_id_map = {int(l.split()[0]): idx+1 for idx, l in enumerate(ligand_atom_lines)}\n",
    "\n",
    "    # --- extract ligand bond ---\n",
    "    ligand_bond_lines = []\n",
    "    bond_num = 1\n",
    "    for l in bond_lines:\n",
    "        fields = l.split()\n",
    "        if len(fields) < 4: # skip protein bonds\n",
    "            continue\n",
    "        a1, a2 = int(fields[1]), int(fields[2])\n",
    "        if a1 in ligand_atom_ids_set and a2 in ligand_atom_ids_set:\n",
    "            new_a1 = ligand_atom_id_map[a1]\n",
    "            new_a2 = ligand_atom_id_map[a2]\n",
    "            new_line = f\"{bond_num:>6} {new_a1:>5} {new_a2:>5} {fields[3]}\"\n",
    "            if len(fields) > 4:\n",
    "                new_line += \" \" + \" \".join(fields[4:])\n",
    "            ligand_bond_lines.append(new_line + \"\\n\")\n",
    "            bond_num += 1\n",
    "\n",
    "    # --- Save ligand mol2 ---\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(\"@<TRIPOS>MOLECULE\\n\")\n",
    "        f.write(f\"{mol2_path.parent.stem}\\n\")\n",
    "        f.write(f\"{len(ligand_atom_lines)} {len(ligand_bond_lines)} 1\\n\")\n",
    "        f.write(\"SMALL\\n\")\n",
    "        f.write(\"USER_CHARGES\\n\\n\")\n",
    "\n",
    "        f.write(\"@<TRIPOS>ATOM\\n\")\n",
    "        for idx, line in enumerate(ligand_atom_lines, 1):\n",
    "            tokens = line.split()\n",
    "            atom_id = idx\n",
    "            atom_name = tokens[1]\n",
    "            x, y, z = map(float, tokens[2:5])\n",
    "            atom_type = tokens[5]\n",
    "            resid = tokens[6]\n",
    "            resname = tokens[7]\n",
    "            charge = float(tokens[8]) if len(tokens) > 8 else 0.0\n",
    "\n",
    "            formatted = f\"{atom_id:>7} {atom_name:<8} {x:>10.4f} {y:>10.4f} {z:>10.4f} \"\n",
    "            formatted += f\"{atom_type:<6} {resid:>5} {resname:<8} {charge:>9.4f}\\n\"\n",
    "            f.write(formatted)\n",
    "\n",
    "        f.write(\"@<TRIPOS>BOND\\n\")\n",
    "        for line in ligand_bond_lines:\n",
    "            f.write(line)\n",
    "    \n",
    "    print(f\"Ligand saved: {output_path}\")\n",
    "    complex = to_pdb_format(atom_lines, bond_lines, chain_lines)\n",
    "    ligand =  ligand_reader(ligand_atom_lines)\n",
    "    pocket = find_pocket_residues(complex, ligand)\n",
    "    write_pocket_to_mol2(pocket, output_path.parent / 'pocket_atoms.mol2')\n",
    "    print('Pocket saved: ', output_path.parent / 'pocket_atoms.mol2')\n",
    "    return pocket\n",
    "\n",
    "# pk = read_csar(holo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 72mins\n",
    "no_csar = []\n",
    "new_csar = []\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "def sequence_reader(df):\n",
    "    atom_end = df[df['record'] == 'ATOM'].index[-1]\n",
    "    main_structure = df[:atom_end]\n",
    "    read, ridx, r_ridx = read_residue(df[:atom_end][['res_name', 'chain_id', 'res_seq', 'i_code']].values)\n",
    "    return main_structure, read, ridx, r_ridx\n",
    "\n",
    "\n",
    "def find_root_atom(df):\n",
    "    return df[df['atom_name'] == 'CA'][['chain_id', 'res_seq', 'i_code']].values\n",
    "\n",
    "\n",
    "def find_atom(df, keys):\n",
    "    result = []\n",
    "    for k in keys:\n",
    "        result.append(df[(df['chain_id'] == k[0]) & (df['res_seq'] == k[1]) & (df['i_code'] == k[2])])\n",
    "    result = pd.concat(result).reset_index(drop=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "count = 0\n",
    "max_mutation = 0\n",
    "\n",
    "rmsd_results = {}\n",
    "apo_path = Path('data/raw/afdb')\n",
    "holo_path = Path('data/raw/pdb')\n",
    "\n",
    "# output path\n",
    "apo_align_path = Path('data/raw/af_align')\n",
    "apo_align_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "mutant_path = Path('data/raw/mutant')\n",
    "mutant_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "a2h_path = Path('data/processed/a2h')\n",
    "a2h_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# main loop\n",
    "num = 0\n",
    "for idx, row in data.iterrows():\n",
    "    pdb = row['PDB']\n",
    "    uni = row['UniProt']\n",
    "    st = row['SET']\n",
    "\n",
    "    # logging.info(f\"\\n[{idx+1}/{len(data)}] Processing code: {pdb}\")\n",
    "    \n",
    "    if pdb in no_match:\n",
    "        continue\n",
    "\n",
    "    if st == 'PDB':\n",
    "        continue\n",
    "    \n",
    "    elif st != 'CSAR':\n",
    "        continue\n",
    "        # path\n",
    "        apo = apo_path / f\"AF-{uni}-F1-model_v4.pdb\"    \n",
    "        holo = holo_path / st / pdb / f\"{pdb}_protein.pdb\"\n",
    "        pocket = holo_path / st / pdb / f\"{pdb}_pocket.pdb\"\n",
    "        \n",
    "        # read pdb format\n",
    "        ap = read_pdb(apo)\n",
    "        ho = read_pdb(holo)\n",
    "        pk = read_pdb(pocket)\n",
    "        \n",
    "        # read pocket and parse chain_id from holo\n",
    "        ho_keys = parse_residue_and_align(ho[['res_seq', 'chain_id']].values)\n",
    "        pk['c_key'] = parse_residue_and_align(pk['res_seq'].values, chain=False)\n",
    "        pk['chain_id'] = pk['c_key'].map(ho_keys)\n",
    "        pk = pk.drop(columns=['c_key']).reset_index(drop=True)\n",
    "        pk.loc[pk['res_name'] == 'HOH', 'chain_id'] = ' '\n",
    "\n",
    "    else: # CSAR\n",
    "        # continue # pocket이 잘못만들어짐.. ㅅㅂ 내 시간.. 그냥 mol2파일에서 10옴스트롬이내 추출 ㄱㄱ\n",
    "        \n",
    "        # path\n",
    "        apo = apo_path / f\"AF-{uni}-F1-model_v4.pdb\"\n",
    "        holo = [f for f in(holo_path / st / pdb).glob('*complex.mol2')][0]\n",
    "        pocket = pocket_idx[pocket_idx['PDB'] == pdb]['Residue'].values[0]\n",
    "        \n",
    "        # read for pdb format\n",
    "        ap = read_pdb(apo)\n",
    "        ho = read_mol2(holo)\n",
    "        pk = read_csar(holo)\n",
    "        \n",
    "        # fix csar sequence\n",
    "        pk_seq = sequence_reader(pk)[1]\n",
    "        try:\n",
    "            li = Chem.MolFromMol2File(holo.parent / f'{pdb}_ligand.mol2')\n",
    "            smi = Chem.MolToSmiles(li)\n",
    "        except:\n",
    "            li = Chem.MolFromMol2File(holo.parent / f'{pdb}_ligand_rm_mg.mol2')\n",
    "            smi = Chem.MolToSmiles(li)\n",
    "        row['Pocket'] = pk_seq\n",
    "        row['Pocket_Len'] = len(pk_seq)\n",
    "        row['Ligand'] = smi\n",
    "        row['Ligand_Len'] = len(smi)\n",
    "        new_csar.append(row.to_dict())\n",
    "        \n",
    "        # remove ligand\n",
    "        ho = ho[ho['res_name'] != 'INH'].reset_index(drop=True)\n",
    "\n",
    "    num += 1\n",
    "    if num % 1000 == 0:\n",
    "        print(num)\n",
    "\n",
    "    # # common process\n",
    "    # extract amino acid sequence\n",
    "    ho_main, ho_read, ho_ridx, ho_r_ridx = sequence_reader(ho)\n",
    "    pk_main, pk_read, pk_ridx, pk_r_ridx = sequence_reader(pk)\n",
    "    ap_main, ap_read, ap_ridx, ap_r_ridx = sequence_reader(ap)\n",
    "    # print(len(ho_ridx), ho_read)\n",
    "    # print(len(pk_ridx), pk_read)\n",
    "    # print(len(ap_ridx), ap_read)\n",
    "\n",
    "    # search pocket in holo\n",
    "    pk_ca = find_root_atom(pk_main)\n",
    "    ho_pk = find_atom(ho_main, pk_ca)\n",
    "    ho_ca = find_root_atom(ho_pk)\n",
    "    ho_pk_idx = sorted([ho_ridx[(idx[0], idx[1], idx[2])] for idx in ho_ca])\n",
    "    \n",
    "    # extract pocket amino acids in holo (save position)\n",
    "    ho_pk_read = ho_read[ho_pk_idx[0]:ho_pk_idx[-1]+1]\n",
    "    ho_pk_res_dict = {ho_pk_idx[0] + i:i  for i in range(len(ho_pk_read))}\n",
    "    ho_pk_res_idx = [ho_pk_res_dict[i] for i in ho_pk_idx] # for mutation position\n",
    "    \n",
    "    # sequence alignment (score params: match, mismatch, gap open, gap extension)\n",
    "    alignments = pairwise2.align.localms(ho_pk_read, ap_read, 2, -1, -5, -1)\n",
    "    ho_align, ap_align = alignments[0][:2]\n",
    "\n",
    "    # mapping position & check mutation\n",
    "    mapping_align = {}\n",
    "    align_position = {}\n",
    "    mutations = []\n",
    "    st_pos = ho_pos = ap_pos = -1\n",
    "\n",
    "    for a, b in zip(ho_align, ap_align):\n",
    "        if a != '-':\n",
    "            ho_pos += 1\n",
    "            st_pos += 1\n",
    "        if b != '-':\n",
    "            ap_pos += 1\n",
    "            st_pos += 1\n",
    "        if a != '-' and b != '-':\n",
    "            st_pos += 1\n",
    "            align_position[st_pos] = ho_pos\n",
    "            mapping_align[ho_pos] = ap_pos\n",
    "            if a != b and ho_pos in ho_pk_res_idx:\n",
    "                mutations.append((ap_pos, b, a))\n",
    "                \n",
    "    # check mutation\n",
    "    if mutations:\n",
    "        max_mutation = max(max_mutation, len(mutations))\n",
    "\n",
    "        transform = []\n",
    "        for mut in mutations:\n",
    "            ap_pk_idx, ap_res, ho_res = mut\n",
    "            ap_chain, ap_resid, _ = ap_r_ridx[ap_pk_idx]\n",
    "            transform.append((ap_chain, ap_resid, ap_res, ho_res))\n",
    "        \n",
    "        mut_out = mutant_path / f\"AF-{uni}-mut-{pdb}.pdb\"    \n",
    "        point_mutation(apo, mut_out, transform)\n",
    "\n",
    "        # reload\n",
    "        apo = mut_out\n",
    "        ap = read_pdb(apo)\n",
    "        ap_main, ap_read, ap_ridx, ap_r_ridx = sequence_reader(ap)\n",
    "\n",
    "    try:\n",
    "        # find pocket in apo (ho_pk_idx -> ho_pk_res_dict -> mapping align)\n",
    "        ap_ca = []\n",
    "        rm_ca = []\n",
    "        for i in ho_pk_idx:\n",
    "            hp_key = ho_pk_res_dict[i]  # atom within pocket\n",
    "            if hp_key in mapping_align.keys(): # atom within mapping & pocket\n",
    "                ap_ca.append(ap_r_ridx[mapping_align[hp_key]]) # find \n",
    "            else:\n",
    "                rm_ca.append(i)\n",
    "        if rm_ca: # select atom atoms only in apo\n",
    "            ho_pk = find_atom(ho_main, [ho_r_ridx[i] for i in ho_pk_idx if not i in rm_ca])\n",
    "        ap_pk = find_atom(ap_main, ap_ca) # find pocket in apo\n",
    "    except:\n",
    "        print(pdb)\n",
    "        print(format_alignment(*alignments[0]))\n",
    "        no_csar.append(pdb)\n",
    "        continue\n",
    "\n",
    "    # superimpose\n",
    "    align_out = apo_align_path / f\"AF-{uni}-align-{pdb}.pdb\"\n",
    "    rmsd = align_and_save(apo, holo, align_out)\n",
    "    rmsd_results[pdb] = rmsd\n",
    "    \n",
    "    # mutated & aligned apo structure\n",
    "    aa = read_pdb(align_out)\n",
    "    aa_main, aa_read, aa_ridx, aa_r_ridx = sequence_reader(aa)\n",
    "    aa_pk = find_atom(aa_main, ap_ca)\n",
    "    \n",
    "    # save\n",
    "    a2h_out = a2h_path / f\"{pdb}_a2h.pkl\"\n",
    "    a2h = {'APO': aa_pk, 'HOLO': ho_pk}\n",
    "    with open(a2h_out, 'wb') as f:\n",
    "        pd.to_pickle(a2h, f)\n",
    "\n",
    "    # if len(mutations) >= 1:\n",
    "    #     print(pdb)\n",
    "    #     print(format_alignment(*alignments[0]))\n",
    "    #     print(sequence_reader(ho_pk)[1])\n",
    "    #     print(sequence_reader(ap_pk)[1])        \n",
    "    #     print()\n",
    "    #     break\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(new_csar).to_csv('data/fix_csar.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search largest vector\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "def find_largest_vector(directory):\n",
    "    directory = Path(directory)\n",
    "    max_count = 0\n",
    "    max_ca = 0\n",
    "    max_file = None\n",
    "    max_ca_file = None\n",
    "\n",
    "    with open(a2h_path / f\"{intereset}_a2h.pkl\", 'rb') as f:\n",
    "        lb = pd.read_pickle(f)\n",
    "        count = len(data['APO'])\n",
    "        ca = pd.DataFrame(data['APO'])\n",
    "        ca = ca[ca['atom_name'] == 'CA']\n",
    "        if count > max_count:\n",
    "            max_count = count\n",
    "            max_file = pkl_file\n",
    "        \n",
    "        ca_count = len(ca)\n",
    "        if ca_count > max_ca:\n",
    "            max_ca = ca_count\n",
    "            max_ca_file = pkl_file\n",
    "\n",
    "    print(f\"Largest vector: {max_file.name} with {max_count} entries\")\n",
    "    print(f\"Largest CA vector: {max_ca_file.name} with {max_ca} entries\")\n",
    "\n",
    "find_largest_vector(\"data/raw/af_align\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def find_files_with_coord_diff(directory, threshold=1e-3):\n",
    "    directory = Path(directory)\n",
    "    files_with_diff = []\n",
    "\n",
    "    for pkl_file in directory.glob(\"*.pkl\"):\n",
    "        with open(pkl_file, \"rb\") as f:\n",
    "            data = pickle.load(f)\n",
    "        apo = pd.DataFrame(data['APO'])\n",
    "        holo = pd.DataFrame(data['HOLO'])\n",
    "\n",
    "        # 기준: res_seq, atom_name이 같은 원자끼리 좌표 비교\n",
    "        merged = pd.merge(\n",
    "            apo, holo,\n",
    "            on=['res_seq', 'atom_name'],\n",
    "            suffixes=('_apo', '_holo')\n",
    "        )\n",
    "\n",
    "        # coord 컬럼에서 좌표 추출\n",
    "        def extract_coords(row, prefix):\n",
    "            return np.array(row[f'coord_{prefix}'])\n",
    "\n",
    "        # 좌표 차이 계산\n",
    "        merged['coord_diff'] = merged.apply(\n",
    "            lambda row: np.linalg.norm(\n",
    "                extract_coords(row, 'apo') - extract_coords(row, 'holo')\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "        # 임계값(threshold) 이상 차이가 있는 경우\n",
    "        if (merged['coord_diff'] > threshold).any():\n",
    "            files_with_diff.append(pkl_file.name)\n",
    "\n",
    "    print(f\"Files with coordinate differences (>{threshold} Å):\")\n",
    "    for fname in files_with_diff:\n",
    "        print(fname)\n",
    "\n",
    "find_files_with_coord_diff(\"APO_to_Holo\", threshold=0.1)  # 0.1Å 이상 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 72mins\n",
    "final_data = []\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from Bio import pairwise2\n",
    "from Bio.pairwise2 import format_alignment\n",
    "\n",
    "def sequence_reader(df):\n",
    "    atom_end = df[df['record'] == 'ATOM'].index[-1]\n",
    "    main_structure = df[:atom_end]\n",
    "    read, ridx, r_ridx = read_residue(df[:atom_end][['res_name', 'chain_id', 'res_seq', 'i_code']].values)\n",
    "    return main_structure, read, ridx, r_ridx\n",
    "\n",
    "\n",
    "def find_root_atom(df):\n",
    "    return df[df['atom_name'] == 'CA'][['chain_id', 'res_seq', 'i_code']].values\n",
    "\n",
    "\n",
    "def find_atom(df, keys):\n",
    "    result = []\n",
    "    for k in keys:\n",
    "        result.append(df[(df['chain_id'] == k[0]) & (df['res_seq'] == k[1]) & (df['i_code'] == k[2])])\n",
    "    result = pd.concat(result).reset_index(drop=True)\n",
    "    return result\n",
    "\n",
    "\n",
    "count = 0\n",
    "max_mutation = 0\n",
    "\n",
    "rmsd_results = {}\n",
    "apo_path = Path('data/raw/afdb')\n",
    "holo_path = Path('data/raw/pdb')\n",
    "\n",
    "# output path\n",
    "apo_align_path = Path('data/raw/af_align')\n",
    "apo_align_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "mutant_path = Path('data/raw/mutant')\n",
    "mutant_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "a2h_path = Path('data/processed/a2h')\n",
    "a2h_path.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# main loop\n",
    "num = 0\n",
    "for idx, row in data.iterrows():\n",
    "    pdb = row['PDB']\n",
    "    uni = row['UniProt']\n",
    "    st = row['SET']\n",
    "\n",
    "    if pdb in no_match:\n",
    "        continue\n",
    "\n",
    "    if st == 'PDB':\n",
    "        continue\n",
    "    \n",
    "    elif st != 'CSAR':\n",
    "        final_data.append(row.to_dict())\n",
    "\n",
    "        # path\n",
    "        apo = apo_path / f\"AF-{uni}-F1-model_v4.pdb\"    \n",
    "        holo = holo_path / st / pdb / f\"{pdb}_protein.pdb\"\n",
    "        pocket = holo_path / st / pdb / f\"{pdb}_pocket.pdb\"\n",
    "        \n",
    "        # read pdb format\n",
    "        ap = read_pdb(apo)\n",
    "        ho = read_pdb(holo)\n",
    "        pk = read_pdb(pocket)\n",
    "        \n",
    "        # read pocket and parse chain_id from holo\n",
    "        ho_keys = parse_residue_and_align(ho[['res_seq', 'chain_id']].values)\n",
    "        pk['c_key'] = parse_residue_and_align(pk['res_seq'].values, chain=False)\n",
    "        pk['chain_id'] = pk['c_key'].map(ho_keys)\n",
    "        pk = pk.drop(columns=['c_key']).reset_index(drop=True)\n",
    "        pk.loc[pk['res_name'] == 'HOH', 'chain_id'] = ' '\n",
    "\n",
    "    else: # CSAR\n",
    "        \n",
    "        # path\n",
    "        apo = apo_path / f\"AF-{uni}-F1-model_v4.pdb\"\n",
    "        holo = [f for f in(holo_path / st / pdb).glob('*complex.mol2')][0]\n",
    "        pocket = pocket_idx[pocket_idx['PDB'] == pdb]['Residue'].values[0]\n",
    "        \n",
    "        # read for pdb format\n",
    "        ap = read_pdb(apo)\n",
    "        ho = read_mol2(holo)\n",
    "        pk = read_csar(holo)\n",
    "        \n",
    "        # fix csar sequence\n",
    "        pk_seq = sequence_reader(pk)[1]\n",
    "        try:\n",
    "            li = Chem.MolFromMol2File(holo.parent / f'{pdb}_ligand.mol2')\n",
    "            smi = Chem.MolToSmiles(li)\n",
    "        except:\n",
    "            li = Chem.MolFromMol2File(holo.parent / f'{pdb}_ligand_rm_mg.mol2')\n",
    "            smi = Chem.MolToSmiles(li)\n",
    "        row['Pocket'] = pk_seq\n",
    "        row['Pocket_Len'] = len(pk_seq)\n",
    "        row['Ligand'] = smi\n",
    "        row['Ligand_Len'] = len(smi)\n",
    "        final_data.append(row.to_dict())\n",
    "        \n",
    "        # remove ligand\n",
    "        ho = ho[ho['res_name'] != 'INH'].reset_index(drop=True)\n",
    "\n",
    "    num += 1\n",
    "    if num % 1000 == 0:\n",
    "        print(num)\n",
    "\n",
    "    logging.info(f\"\\n[{idx+1}/{len(data)}] Processing code: {pdb}\")\n",
    "\n",
    "    # # common process\n",
    "    # extract amino acid sequence\n",
    "    ho_main, ho_read, ho_ridx, ho_r_ridx = sequence_reader(ho)\n",
    "    pk_main, pk_read, pk_ridx, pk_r_ridx = sequence_reader(pk)\n",
    "    ap_main, ap_read, ap_ridx, ap_r_ridx = sequence_reader(ap)\n",
    "    # print(len(ho_ridx), ho_read)\n",
    "    # print(len(pk_ridx), pk_read)\n",
    "    # print(len(ap_ridx), ap_read)\n",
    "\n",
    "    # search pocket in holo\n",
    "    pk_ca = find_root_atom(pk_main)\n",
    "    ho_pk = find_atom(ho_main, pk_ca)\n",
    "    ho_ca = find_root_atom(ho_pk)\n",
    "    ho_pk_idx = sorted([ho_ridx[(idx[0], idx[1], idx[2])] for idx in ho_ca])\n",
    "    \n",
    "    # extract pocket amino acids in holo (save position)\n",
    "    ho_pk_read = ho_read[ho_pk_idx[0]:ho_pk_idx[-1]+1]\n",
    "    ho_pk_res_dict = {ho_pk_idx[0] + i:i  for i in range(len(ho_pk_read))}\n",
    "    ho_pk_res_idx = [ho_pk_res_dict[i] for i in ho_pk_idx] # for mutation position\n",
    "    \n",
    "    # sequence alignment (score params: match, mismatch, gap open, gap extension)\n",
    "    alignments = pairwise2.align.localms(ho_pk_read, ap_read, 2, -1, -5, -1)\n",
    "    ho_align, ap_align = alignments[0][:2]\n",
    "\n",
    "    # mapping position & check mutation\n",
    "    mapping_align = {}\n",
    "    align_position = {}\n",
    "    mutations = []\n",
    "    st_pos = ho_pos = ap_pos = -1\n",
    "\n",
    "    for a, b in zip(ho_align, ap_align):\n",
    "        if a != '-':\n",
    "            ho_pos += 1\n",
    "            st_pos += 1\n",
    "        if b != '-':\n",
    "            ap_pos += 1\n",
    "            st_pos += 1\n",
    "        if a != '-' and b != '-':\n",
    "            st_pos += 1\n",
    "            align_position[st_pos] = ho_pos\n",
    "            mapping_align[ho_pos] = ap_pos\n",
    "            if a != b and ho_pos in ho_pk_res_idx:\n",
    "                mutations.append((ap_pos, b, a))\n",
    "                \n",
    "    # check mutation\n",
    "    if mutations:\n",
    "        max_mutation = max(max_mutation, len(mutations))\n",
    "\n",
    "        transform = []\n",
    "        for mut in mutations:\n",
    "            ap_pk_idx, ap_res, ho_res = mut\n",
    "            ap_chain, ap_resid, _ = ap_r_ridx[ap_pk_idx]\n",
    "            transform.append((ap_chain, ap_resid, ap_res, ho_res))\n",
    "        \n",
    "        mut_out = mutant_path / f\"AF-{uni}-mut-{pdb}.pdb\"    \n",
    "        point_mutation(apo, mut_out, transform)\n",
    "\n",
    "        # reload\n",
    "        apo = mut_out\n",
    "        ap = read_pdb(apo)\n",
    "        ap_main, ap_read, ap_ridx, ap_r_ridx = sequence_reader(ap)\n",
    "    \n",
    "    # find pocket in apo (ho_pk_idx -> ho_pk_res_dict -> mapping align)\n",
    "    ap_ca = []\n",
    "    rm_ca = []\n",
    "    for i in ho_pk_idx:\n",
    "        hp_key = ho_pk_res_dict[i]  # atom within pocket\n",
    "        if hp_key in mapping_align.keys(): # atom within mapping & pocket\n",
    "            ap_ca.append(ap_r_ridx[mapping_align[hp_key]]) # find \n",
    "        else:\n",
    "            rm_ca.append(i)\n",
    "    if rm_ca: # select atom atoms only in apo\n",
    "        ho_pk = find_atom(ho_main, [ho_r_ridx[i] for i in ho_pk_idx if not i in rm_ca])\n",
    "    ap_pk = find_atom(ap_main, ap_ca) # find pocket in apo\n",
    "\n",
    "    # superimpose\n",
    "    align_out = apo_align_path / f\"AF-{uni}-align-{pdb}.pdb\"\n",
    "    rmsd = align_and_save(apo, holo, align_out)\n",
    "    rmsd_results[pdb] = rmsd\n",
    "    \n",
    "    # mutated & aligned apo structure\n",
    "    aa = read_pdb(align_out)\n",
    "    aa_main, aa_read, aa_ridx, aa_r_ridx = sequence_reader(aa)\n",
    "    aa_pk = find_atom(aa_main, ap_ca)\n",
    "    \n",
    "    # save\n",
    "    a2h_out = a2h_path / f\"{pdb}_a2h.pkl\"\n",
    "    a2h = {'APO': aa_pk, 'HOLO': ho_pk}\n",
    "    with open(a2h_out, 'wb') as f:\n",
    "        pd.to_pickle(a2h, f)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/raw/rmsd_results.txt', 'w') as f:\n",
    "    for k, v in rmsd_results.items():\n",
    "        f.write(f\"{k}: {v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = pd.DataFrame(final_data)\n",
    "final.to_csv('data/final.csv', index=False, header=True)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = final[~final['PDB'].isin(no_match)]\n",
    "final['SET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final[final['SET'] == 'Refined']['UniProt'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_pdbs = [f.stem.split('-')[3] for f in apo_align_path.glob('*.pdb')]\n",
    "len(align_pdbs) # exclude 29 pdbs (no_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "general = final[final['SET'] == 'General']\n",
    "refined = final[final['SET'] == 'Refined']\n",
    "\n",
    "seeds = [42, 100, 123, 456, 789]\n",
    "for idx, seed in enumerate(seeds):\n",
    "    # minimum sample per UniProt\n",
    "    num_uni = refined['UniProt'].nunique()\n",
    "    samples_per_uni = 1000 // num_uni\n",
    "\n",
    "    # sampling each UniProt (maximum samples_per_uni)\n",
    "    sampled = refined.groupby('UniProt', group_keys=False).apply(\n",
    "        lambda x: x.sample(n=min(samples_per_uni, len(x)), random_state=seed)\n",
    "    )\n",
    "\n",
    "    # remaining samples\n",
    "    remaining = 1000 - len(sampled)\n",
    "    if remaining > 0:\n",
    "        additional = refined[~refined.index.isin(sampled.index)].sample(n=remaining, random_state=seed)\n",
    "        valid = pd.concat([sampled, additional])\n",
    "\n",
    "    #check \n",
    "    valid['UniProt'].value_counts()\n",
    "\n",
    "    # create training set\n",
    "    remain_refined = refined[~refined.index.isin(valid.index)]\n",
    "    train = pd.concat([general, remain_refined]).reset_index(drop=True)\n",
    "\n",
    "    # extract pdb list\n",
    "    train_pdb = train['PDB'].tolist()\n",
    "    valid_pdb = valid['PDB'].tolist()\n",
    "    fold_pdb = {'SEED': seed, 'TRN': train_pdb, 'VAL': valid_pdb}\n",
    "\n",
    "    # save\n",
    "    with open(f'cache/fold_{idx+1}.json', 'w') as f:\n",
    "        json.dump(fold_pdb, f)\n",
    "    \n",
    "    # check\n",
    "    print(f'Fold {idx+1}: Seed {seed}')\n",
    "    print(len(train), len(valid))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
